{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f606e-cae9-4c97-9cfc-9de8f3140b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependencies>\n",
    "    <dependency>\n",
    "        <groupId>ai.djl</groupId>\n",
    "        <artifactId>api</artifactId>\n",
    "        <version>0.20.0</version>\n",
    "    </dependency>\n",
    "    <dependency>\n",
    "        <groupId>ai.djl.mxnet</groupId>\n",
    "        <artifactId>mxnet-engine</artifactId>\n",
    "        <version>0.20.0</version>\n",
    "    </dependency>\n",
    "    <dependency>\n",
    "        <groupId>ai.djl.paddlepaddle</groupId>\n",
    "        <artifactId>paddlepaddle-model-zoo</artifactId>\n",
    "        <version>0.20.0</version>\n",
    "    </dependency>\n",
    "    <dependency>\n",
    "        <groupId>ai.djl.onnxruntime</groupId>\n",
    "        <artifactId>onnxruntime-engine</artifactId>\n",
    "        <version>0.20.0</version>\n",
    "        <scope>runtime</scope>\n",
    "        <exclusions>\n",
    "            <exclusion>\n",
    "                <groupId>com.microsoft.onnxruntime</groupId>\n",
    "                <artifactId>onnxruntime</artifactId>\n",
    "            </exclusion>\n",
    "        </exclusions>\n",
    "    </dependency>\n",
    "    <dependency>\n",
    "        <groupId>com.microsoft.onnxruntime</groupId>\n",
    "        <artifactId>onnxruntime_gpu</artifactId>\n",
    "        <version>1.13.1</version>\n",
    "        <scope>runtime</scope>\n",
    "    </dependency>\n",
    "    <dependency>\n",
    "        <groupId>ai.djl.opencv</groupId>\n",
    "        <artifactId>opencv</artifactId>\n",
    "        <version>0.20.0</version>\n",
    "    </dependency>\n",
    "    <dependency>\n",
    "        <groupId>org.slf4j</groupId>\n",
    "        <artifactId>slf4j-simple</artifactId>\n",
    "        <version>1.7.36</version>\n",
    "    </dependency>\n",
    "</dependencies>\n",
    "\n",
    "<repositories>\n",
    "    <repository>\n",
    "        <id>aliyun</id>\n",
    "        <url>https://maven.aliyun.com/repository/central</url>\n",
    "    </repository>\n",
    "</repositories>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b0cec88-3762-46bd-b1ab-4c7f1edd04e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ai.djl.MalformedModelException;\n",
    "import ai.djl.modality.cv.Image;\n",
    "import ai.djl.modality.cv.output.DetectedObjects;\n",
    "import ai.djl.repository.zoo.Criteria;\n",
    "import ai.djl.repository.zoo.ModelNotFoundException;\n",
    "import ai.djl.repository.zoo.ZooModel;\n",
    "import ai.djl.training.util.ProgressBar;\n",
    "\n",
    "import java.io.IOException;\n",
    "import java.nio.file.Paths;\n",
    "\n",
    "public class Models {\n",
    "\n",
    "    public static ZooModel<Image, DetectedObjects> getModel() throws ModelNotFoundException, MalformedModelException, IOException {\n",
    "        return Criteria.builder()\n",
    "                .optEngine(\"OnnxRuntime\") // 选择引擎\n",
    "                .setTypes(Image.class, DetectedObjects.class) // 设置输入输出\n",
    "                .optModelPath(Paths.get(\"/root/autodl-nas/pedestrian_yolov3_darknet.onnx\")) // 设置模型地址。Jar 包、Zip 包根据 API 自行配置\n",
    "                .optProgress(new ProgressBar()) // 进度条\n",
    "                .optTranslator(new PedestrianTranslator(.5f)) // 默认的转换器，不是线程安全的\n",
    "                .build().loadModel();\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ddd1f8-99fb-409e-a9e1-acd926474347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ai.djl.modality.cv.Image;\n",
    "import ai.djl.modality.cv.output.BoundingBox;\n",
    "import ai.djl.modality.cv.output.DetectedObjects;\n",
    "import ai.djl.modality.cv.output.Rectangle;\n",
    "import ai.djl.modality.cv.transform.Normalize;\n",
    "import ai.djl.modality.cv.transform.Resize;\n",
    "import ai.djl.modality.cv.transform.ToTensor;\n",
    "import ai.djl.ndarray.NDArray;\n",
    "import ai.djl.ndarray.NDList;\n",
    "import ai.djl.ndarray.NDManager;\n",
    "import ai.djl.ndarray.types.DataType;\n",
    "import ai.djl.translate.NoBatchifyTranslator;\n",
    "import ai.djl.translate.Pipeline;\n",
    "import ai.djl.translate.TranslatorContext;\n",
    "\n",
    "import java.util.ArrayList;\n",
    "import java.util.Collections;\n",
    "import java.util.List;\n",
    "\n",
    "// 非批量输入输出应实现 NoBatchifyTranslator 接口，而不是 Translator\n",
    "public class PedestrianTranslator implements NoBatchifyTranslator<Image, DetectedObjects> {\n",
    "    private final Pipeline pipeline;\n",
    "    private final float threshold;\n",
    "    private final List<String> classes;\n",
    "    private final float imageWidth = 608f;\n",
    "    private final float imageHeight = 608f;\n",
    "\n",
    "    public PedestrianTranslator(float threshold) {\n",
    "        // 定义图片预处理过程\n",
    "        pipeline = new Pipeline();\n",
    "        pipeline.add(new Resize((int) imageWidth, (int) imageHeight)) // resize 到图片输入格式，此时为 608 * 608 * 3，HWC\n",
    "                .add(new ToTensor()) // HWC -> CHW\n",
    "                .add(new Normalize(new float[]{0.485f, 0.456f, 0.406f}, new float[]{0.229f, 0.224f, 0.225f})) // 归一化\n",
    "                .add(array -> array.expandDims(0)); // CHW -> NCHW\n",
    "        // 预测阈值\n",
    "        this.threshold = threshold;\n",
    "        // 类别\n",
    "        classes = Collections.singletonList(\"pedestrian\");\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public NDList processInput(TranslatorContext ctx, Image input) {\n",
    "        // 内存管理器，负责 NDArray 的内存回收\n",
    "        NDManager manager = ctx.getNDManager();\n",
    "        // 通过构造函数定义好的管道把图片转换到模型需要的图片格式。NDList 是一个集合，与 List<NDArray> 类似\n",
    "        NDList ndList = pipeline.transform(new NDList(input.toNDArray(manager, Image.Flag.COLOR)));\n",
    "        // 添加原图尺寸参数\n",
    "        ndList.add(0, manager.create(new float[]{input.getHeight(), input.getWidth()}).expandDims(0));\n",
    "        // 添加原图片尺寸与输入图片尺寸的比值\n",
    "        ndList.add(manager.create(new float[]{input.getHeight() / 608f, input.getWidth() / 608f}).expandDims(0));\n",
    "        return ndList;\n",
    "    }\n",
    "\n",
    "    @Override\n",
    "    public DetectedObjects processOutput(TranslatorContext ctx, NDList list) {\n",
    "        // 获取第一个参数预测结果，第二个预测数量没什么用\n",
    "        NDArray result = list.get(0);\n",
    "        /*\n",
    "        result demo:\n",
    "        ND: (3, 6) cpu() float32\n",
    "        [[  0.    ,   0.9759,  10.0805, 276.1631, 298.1623, 586.246 ],\n",
    "         [  0.    ,   0.955 , 486.306 , 221.0572, 585.966 , 480.4897],\n",
    "         [  0.    ,   0.8031, 295.0543, 206.104 , 395.3066, 485.3789],\n",
    "        ]\n",
    "         */\n",
    "        // 获取类别\n",
    "        int[] classIndices = result.get(\":, 0\").toType(DataType.INT32, true).flatten().toIntArray();\n",
    "        // 获取置信度\n",
    "        double[] probs = result.get(\":, 1\").toType(DataType.FLOAT64, true).toDoubleArray();\n",
    "        // 获取预测的目标数量\n",
    "        int detected = Math.toIntExact(probs.length);\n",
    "\n",
    "        // 获取矩形框左上角 x 坐标比例（第 2 列）\n",
    "        NDArray xMin = result.get(\":, 2:3\").clip(0, imageWidth).div(imageWidth);\n",
    "        // 获取矩形框左上角 y 坐标比例（第 3 列）\n",
    "        NDArray yMin = result.get(\":, 3:4\").clip(0, imageHeight).div(imageHeight);\n",
    "        // 获取矩形框右上角 x 坐标比例（第 4 列）\n",
    "        NDArray xMax = result.get(\":, 4:5\").clip(0, imageWidth).div(imageWidth);\n",
    "        // 获取矩形框右上角 y 坐标比例（第 5 列）\n",
    "        NDArray yMax = result.get(\":, 5:6\").clip(0, imageHeight).div(imageHeight);\n",
    "\n",
    "        // 转为可以直接绘制的数据，分别是矩形框左上角的 x 和 y 坐标、矩形框的宽和高，均为比例\n",
    "        float[] boxX = xMin.toFloatArray();\n",
    "        float[] boxY = yMin.toFloatArray();\n",
    "        float[] boxWidth = xMax.sub(xMin).toFloatArray();\n",
    "        float[] boxHeight = yMax.sub(yMin).toFloatArray();\n",
    "\n",
    "        // 封装到 DetectedObjects 对象输出\n",
    "        List<String> retClasses = new ArrayList<>(detected);\n",
    "        List<Double> retProbs = new ArrayList<>(detected);\n",
    "        List<BoundingBox> retBB = new ArrayList<>(detected);\n",
    "        for (int i = 0; i < detected; i++) {\n",
    "            // 类别不存在或者置信度低于预测阈值则跳过\n",
    "            if (classIndices[i] < 0 || probs[i] < threshold) {\n",
    "                continue;\n",
    "            }\n",
    "            retClasses.add(classes.get(0));\n",
    "            retProbs.add(probs[i]);\n",
    "            retBB.add(new Rectangle(boxX[i], boxY[i], boxWidth[i], boxHeight[i]));\n",
    "        }\n",
    "        return new DetectedObjects(retClasses, retProbs, retBB);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c943f99f-ccce-4773-add8-04b3bdccc656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ai.djl.Device;\n",
    "import ai.djl.MalformedModelException;\n",
    "import ai.djl.inference.Predictor;\n",
    "import ai.djl.modality.cv.Image;\n",
    "import ai.djl.modality.cv.ImageFactory;\n",
    "import ai.djl.modality.cv.output.DetectedObjects;\n",
    "import ai.djl.repository.zoo.ModelNotFoundException;\n",
    "import ai.djl.repository.zoo.ZooModel;\n",
    "import ai.djl.translate.TranslateException;\n",
    "\n",
    "import java.io.IOException;\n",
    "import java.nio.file.Files;\n",
    "import java.nio.file.Paths;\n",
    "\n",
    "public class Inference {\n",
    "    public static void run(String imageFilePath) throws IOException, MalformedModelException, TranslateException, ModelNotFoundException {\n",
    "        // 加载模型\n",
    "        try (ZooModel<Image, DetectedObjects> model = Models.getModel()) {\n",
    "            // 新建一个推理\n",
    "            try (Predictor<Image, DetectedObjects> predictor = model.newPredictor(Device.gpu())) {\n",
    "                Image image = ImageFactory.getInstance().fromFile(Paths.get(imageFilePath));\n",
    "                // 推理\n",
    "                DetectedObjects result = predictor.predict(image);\n",
    "                // 绘制矩形框\n",
    "                image.drawBoundingBoxes(result);\n",
    "                image.save(Files.newOutputStream(Paths.get(\"output.png\")), \"png\");\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1214a-9bfc-45c3-913a-8c12730fec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inference.run(\"/root/autodl-nas/958*604.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.17+8-post-Ubuntu-1ubuntu218.04"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
